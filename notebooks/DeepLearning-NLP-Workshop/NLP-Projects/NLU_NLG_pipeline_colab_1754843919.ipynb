{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# NLU + Retrieval + NLG Mini Pipeline (Colab-Ready)\n", "\n", "This notebook shows:\n", "1. **NLU**: Intent classification with a small DistilBERT fine-tune\n", "2. **Retrieval**: Use predicted intent to fetch a policy snippet\n", "3. **NLG**: Generate a grounded reply with FLAN-T5\n", "4. **Evaluation**: Accuracy/F1 for NLU; ROUGE-L for NLG\n", "\n", "Run top-to-bottom on Google Colab (GPU optional)."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Install deps (Colab)\n", "!pip -q install transformers datasets evaluate accelerate sentencepiece rouge-score\n", "import os, random, numpy as np, torch\n", "from datetime import datetime\n", "print('Torch:', torch.__version__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1) Build a small, realistic intent dataset\n", "- Four intents: `refund`, `order_status`, `complaint`, `change_address`\n", "- We'll create train/validation/test splits for a quick demo."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["from datasets import Dataset, DatasetDict\n", "import random\n", "random.seed(42)\n", "\n", "intents = {0:'refund',1:'order_status',2:'complaint',3:'change_address'}\n", "samples = [\n", "  ('I want a refund for my purchase', 0),\n", "  ('Please process my refund', 0),\n", "  ('How do I return this and get my money back?', 0),\n", "  ('Can I get a refund? The item arrived damaged', 0),\n", "  ('Initiate refund request', 0),\n", "  ('I returned the item; when will I receive a refund?', 0),\n", "  ('Where is my order?', 1),\n", "  ('Has my package shipped yet?', 1),\n", "  ('Track my delivery please', 1),\n", "  ('What is the current status of my order?', 1),\n", "  ('Provide my tracking number', 1),\n", "  ('Expected delivery date for order 123?', 1),\n", "  ('This product is terrible', 2),\n", "  ('I want to file a complaint about the service', 2),\n", "  ('Your support was unhelpful', 2),\n", "  ('I am unhappy with the quality', 2),\n", "  ('The item is faulty and I am frustrated', 2),\n", "  ('I need to escalate a complaint', 2),\n", "  ('I need to change my shipping address', 3),\n", "  ('Update my delivery address please', 3),\n", "  ('Can I modify the address for my order?', 3),\n", "  ('Change the destination address', 3),\n", "  ('Change address before it ships', 3),\n", "  ('Please correct my street address', 3),\n", "]\n", "random.shuffle(samples)\n", "texts = [s[0] for s in samples]\n", "labels = [s[1] for s in samples]\n", "dataset = Dataset.from_dict({'text': texts, 'label': labels})\n", "dataset = dataset.train_test_split(test_size=0.25, seed=42)\n", "temp = dataset['train'].train_test_split(test_size=0.2, seed=42)\n", "datasets = DatasetDict(train=temp['train'], validation=temp['test'], test=dataset['test'])\n", "datasets"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2) NLU: DistilBERT fine-tuning for intent classification"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n", "from transformers import TrainingArguments, Trainer\n", "import evaluate\n", "\n", "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n", "\n", "def tok(batch):\n", "    return tokenizer(batch['text'], truncation=True, padding='max_length', max_length=64)\n", "\n", "tokenized = datasets.map(tok, batched=True)\n", "tokenized = tokenized.remove_columns(['text'])\n", "tokenized.set_format('torch')\n", "\n", "model_nlu = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=4)\n", "\n", "accuracy = evaluate.load('accuracy')\n", "f1 = evaluate.load('f1')\n", "\n", "def compute_metrics(eval_pred):\n", "    logits, labels = eval_pred\n", "    import numpy as np\n", "    preds = np.argmax(logits, axis=-1)\n", "    return {\n", "        'accuracy': accuracy.compute(predictions=preds, references=labels)['accuracy'],\n", "        'f1_macro': f1.compute(predictions=preds, references=labels, average='macro')['f1']\n", "    }\n", "\n", "args = TrainingArguments(\n", "    output_dir='nlu_out',\n", "    evaluation_strategy='epoch',\n", "    save_strategy='no',\n", "    learning_rate=5e-5,\n", "    per_device_train_batch_size=8,\n", "    per_device_eval_batch_size=8,\n", "    num_train_epochs=2,\n", "    weight_decay=0.01,\n", "    seed=42,\n", "    logging_steps=5,\n", ")\n", "\n", "trainer = Trainer(\n", "    model=model_nlu,\n", "    args=args,\n", "    train_dataset=tokenized['train'],\n", "    eval_dataset=tokenized['validation'],\n", "    tokenizer=tokenizer,\n", "    compute_metrics=compute_metrics\n", ")\n", "trainer.train()\n", "eval_metrics = trainer.evaluate(tokenized['test'])\n", "eval_metrics"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3) Retrieval: use predicted intent to fetch a policy snippet\n", "Swap this dict for your own retriever in production."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import torch\n", "label_map = {0:'refund',1:'order_status',2:'complaint',3:'change_address'}\n", "kb = {\n", "  'refund': 'You can request a refund within 30 days of delivery. Refunds are issued within 5 business days after inspection.',\n", "  'order_status': 'Track your order with the tracking link emailed after shipment. Typical delivery is 3\u20135 business days.',\n", "  'complaint': 'We are sorry for the trouble. Provide your order ID and details so we can investigate and make it right.',\n", "  'change_address': 'You can change the delivery address before the order ships. Contact support with the correct address.'\n", "}\n", "def predict_intent(text):\n", "    enc = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n", "    with torch.no_grad():\n", "        logits = model_nlu(**enc).logits\n", "    pred = int(torch.argmax(logits, dim=-1).item())\n", "    return label_map[pred]\n", "user_msg = \"I'd like to return my item; the size is wrong.\"\n", "intent = predict_intent(user_msg)\n", "context = kb[intent]\n", "intent, context"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4) NLG: Generate a grounded response with FLAN-T5"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["from transformers import pipeline\n", "generator = pipeline('text2text-generation', model='google/flan-t5-base')\n", "prompt = (\n", "  f\"You are a support agent. Using the policy below, write a concise, friendly response to the customer.\\n\"\n", "  f\"Customer: {user_msg}\\n\"\n", "  f\"Policy: {context}\\n\"\n", "  f\"Response:\" )\n", "reply = generator(prompt, max_length=120, do_sample=False)[0]['generated_text']\n", "print(reply)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5) NLG Evaluation: ROUGE-L vs. a simple reference"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import evaluate\n", "rouge = evaluate.load('rouge')\n", "reference = \"You can request a refund within 30 days. Refunds are processed within 5 business days after we receive the item.\"\n", "scores = rouge.compute(predictions=[reply], references=[reference])\n", "scores"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6) Inference helper: end-to-end function"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["def respond(user_text):\n", "    intent = predict_intent(user_text)\n", "    context = kb[intent]\n", "    prompt = (\n", "      f\"You are a support agent. Using the policy below, write a concise, friendly response to the customer.\\n\"\n", "      f\"Customer: {user_text}\\n\"\n", "      f\"Policy: {context}\\n\"\n", "      f\"Response:\" )\n", "    out = generator(prompt, max_length=120, do_sample=False)[0]['generated_text']\n", "    return {'intent': intent, 'policy': context, 'reply': out}\n", "respond(\"My package hasn't arrived. Can you tell me where it is?\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Notes\n", "- This is a **toy** dataset; for robust NLU, use a larger labeled set (Banking77/CLINC150).\n", "- For production NLG, add **grounding** (RAG), **templates**, and **post-gen checks**.\n", "- Consider LoRA/PEFT for faster/cheaper fine-tuning.\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 5}