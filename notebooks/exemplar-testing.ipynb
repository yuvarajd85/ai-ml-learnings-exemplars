{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d27a70e0-beb6-4c49-b771-5808b8b89646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import tensorflow as tf\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9678d21b-670a-4261-8ba0-9605e23fcf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xxl\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xxl\")\n",
    "\n",
    "input_text = \"translate English to french: How old are you?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1740dbb-c6e9-45a3-bd58-ccdc6d9884b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d8085aedef4929935b1aa3b6588ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b243d74e2b47aa96599015b4a63305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5daa670db45c43079ed00e04963f28aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897656d1956643aaa9356829eaead585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5753fe36f7e845789ed4bf628d55d296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370292bea1454e829c9e3bd41294c118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained text generation model\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a9178a-d9c9-4f93-b2fc-4981e5788846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for structured text generation\n",
    "def generate_text(prompt):\n",
    "    response = generator(prompt, max_length=50, num_return_sequences=1)\n",
    "    return response[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0f943d-520e-4c4a-bb21-4fbe68cdacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompts\n",
    "prompts = [\n",
    "    \"length of employee_id is equal to 5\",\n",
    "    \"value of salary greater than 0\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d0091d-c06e-4d40-8c15-2350fb1779bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: length of employee_id is equal to 5\n",
      "Response: length of employee_id is equal to 5. This is known as a T0. It corresponds to an initial 0. T0 is the end of time.\n",
      "\n",
      "In this paper we will compare the performance of this algorithm and the previous one\n",
      "\n",
      "Prompt: value of salary greater than 0\n",
      "Response: value of salary greater than 0.30, $24.86 an hour, with a maximum rate of $18.50. A minimum age for an individual is 50 years old. In addition, any amount paid to a medical provider shall be taxable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate responses\n",
    "for prompt in prompts:\n",
    "    generated_response = generate_text(prompt)\n",
    "    print(f\"Prompt: {prompt}\\nResponse: {generated_response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c81e7-7007-4514-b1b9-e1ce70328b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
