{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "617c804f-3829-4cd8-afb0-6a22925a451e",
   "metadata": {},
   "source": [
    "# Understanding Agentic RAG\n",
    "\n",
    "## What is RAG?\n",
    "RAG stands for **Retrieval-Augmented Generation**.  \n",
    "It means an AI model doesn‚Äôt rely only on what it already knows internally.  \n",
    "Instead, it does two things:\n",
    "- **Retrieves** information from external sources (like documents, databases, or APIs).  \n",
    "- **Augments** its answer with that retrieved information to give a more accurate response.  \n",
    "\n",
    "---\n",
    "\n",
    "## What is Agentic RAG?\n",
    "Agentic RAG is an advanced version of RAG where the model behaves more like an **agent** that can plan and act in multiple steps.  \n",
    "\n",
    "The process looks like this:\n",
    "1. **Plan** ‚Üí The model decides what information it needs.  \n",
    "2. **Retrieve** ‚Üí It searches for relevant information from external sources.  \n",
    "3. **Reason** ‚Üí It checks if the information is enough.  \n",
    "4. **Loop** ‚Üí If the information is missing, it refines the query and searches again.  \n",
    "5. **Answer** ‚Üí Finally, it generates a well-informed and complete response.  \n",
    "\n",
    "---\n",
    "\n",
    "## Analogy\n",
    "- **Plain RAG**: Like asking a friend one question and they go to the library once, grab a book, and give you an answer.  \n",
    "- **Agentic RAG**: Like asking a friend who is willing to make several trips to the library, check indexes, compare different sources, and then give you a much better, researched answer.  \n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaway\n",
    "- **RAG** = Retrieve once, then answer.  \n",
    "- **Agentic RAG** = Think, plan, retrieve multiple times, and then answer.  \n",
    "- This makes Agentic RAG more powerful and reliable for complex tasks that need multiple steps of reasoning.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa6fa9a-66f7-41b6-8e9b-d8addca402d9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![Agentic Rag Workflow](AGENTIC_RAG.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bcef91-6839-484a-8577-00a400d0287b",
   "metadata": {},
   "source": [
    "### Agentic Langgraph Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c909e05-95e7-4dd6-9305-3b4b8f64f58c",
   "metadata": {},
   "source": [
    "<img src=\"AGENTIC_RAG_LANGGRAPH.png\" alt=\"Uploaded Picture\" width=\"300\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e08a442-9333-40e2-a971-ae018896e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install faiss-cpu\n",
    "# !pip install langgraph\n",
    "# !pip install langchain\n",
    "# !pip install langchain-core\n",
    "# !pip install langchain-community'\n",
    "# !pip install langchain-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da2985b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# üîë Load Environment Variables and API Key\n",
    "# ------------------------------------------\n",
    "\n",
    "# 1. Import required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 2. Load variables from the .env file into environment\n",
    "load_dotenv()\n",
    "\n",
    "# 3. Set OpenAI API key from environment\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c96f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# üì¶ Import Required Libraries for LangChain Setup\n",
    "# ------------------------------------------------\n",
    "\n",
    "# üîπ Load documents from the web\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# üîπ Vector database (FAISS) for storing embeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# üîπ OpenAI embeddings (turn text into vectors)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# üîπ Text splitter for breaking documents into chunks\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "706e2335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 3 documents from 3 URLs\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# üåê Load Documents from Web Sources\n",
    "# ------------------------------------------------\n",
    "\n",
    "# 1. Define list of URLs to fetch content from\n",
    "langgraph_urls = [\n",
    "    \"https://www.analyticsvidhya.com/blog/2024/07/langgraph-revolutionizing-ai-agent/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/workflows/\",\n",
    "    \"https://medium.com/cyberark-engineering/building-production-ready-ai-agents-with-langgraph-a-real-life-use-case-7bda34c7f4e4\"\n",
    "]\n",
    "\n",
    "# 2. Load documents from each URL using WebBaseLoader\n",
    "docs=[WebBaseLoader(url).load() for url in langgraph_urls]\n",
    "print(f\"‚úÖ Loaded {len(docs)} documents from {len(langgraph_urls)} URLs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1040fd6-de61-4c24-85c1-6b0717641cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded: 3\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# üóÇÔ∏è Flatten the List of Documents\n",
    "# ------------------------------------------------\n",
    "\n",
    "# docs currently looks like: [[doc1, doc2], [doc3], [doc4, doc5, ...]]\n",
    "# We need a single flat list of documents\n",
    "\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "print(f\"Total documents loaded: {len(docs_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a08aee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 135\n",
      "‚úÖ Vectorstore and retriever are ready!\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# ‚úÇÔ∏è Step 1: Split Documents into Chunks\n",
    "# ------------------------------------------------\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Define how big each chunk should be (and overlap for context continuity)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,   # max characters per chunk\n",
    "    chunk_overlap=100  # overlap between chunks for smoother context\n",
    ")\n",
    "\n",
    "# Apply splitter to our flattened list of documents\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "print(f\"Total chunks created: {len(doc_splits)}\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# üóÑÔ∏è Step 2: Create Vector Database (FAISS)\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Build FAISS vectorstore from document chunks\n",
    "vectorstore_langgraph = FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# üîç Step 3: Create a Retriever\n",
    "# ------------------------------------------------\n",
    "retriever = vectorstore_langgraph.as_retriever()\n",
    "\n",
    "print(\"‚úÖ Vectorstore and retriever are ready!\")\n",
    "                                                                                       # search_kwargs={\"k\": 3,\"score_threshold\": 0.7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a345380f-dbc7-4da6-9b01-64e887d236fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Source: https://jordan-mungujakisa.medium.com/creating-an-ai-blog-post-generator-with-langchain-a-step-by-step-guide-b96e896c89c0\n",
      "concept of workflows. A workflow is basically a series of pre-determined steps that are carried out with the aim of achieving an end goal using AI. The workflow that impressed me the most was the SEO(Search engine optimization) Optimized Blog Generator workflow, which basically searches the web, picks the top 3 search results, analyses their structure, generates questions, blog title, blog outline and finally the final blog. And I thought this would be a great opportunity to use LangChain to\n",
      "--------------------------------------------------------------------------------\n",
      "[2] Source: https://python.langchain.com/docs/tutorials/\n",
      "Refer to the how-to guides for more detail on using all LangChain components. Orchestration‚Äã Get started using LangGraph to assemble LangChain components into full-featured applications.\n",
      "--------------------------------------------------------------------------------\n",
      "[3] Source: https://jordan-mungujakisa.medium.com/creating-an-ai-blog-post-generator-with-langchain-a-step-by-step-guide-b96e896c89c0\n",
      "Creating an AI Blog Post Generator with LangChain: A Step-by-Step Guide | by Jordan Mungujakisa | MediumSitemapOpen in appSign upSign inMedium LogoWriteSign upSign inCreating an AI Blog Post Generator with LangChain: A Step-by-Step GuideJordan Mungujakisa6 min read¬∑Jun 7, 2024--2ListenSharePress enter or click to view image in full sizeThere is an AI content creation tool called copy.ai that has a concept of workflows. A workflow is basically a series of pre-determined steps that are carried out\n",
      "--------------------------------------------------------------------------------\n",
      "[4] Source: https://python.langchain.com/docs/tutorials/\n",
      "Evaluate your LLM application Edit this pagePreviousIntroductionNextBuild a Question Answering application over a Graph DatabaseGet startedOrchestrationLangSmithEvaluationCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2025 LangChain, Inc.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# üîç Ask the retriever (tuned) and show readable results\n",
    "# ------------------------------------------------\n",
    "\n",
    "\n",
    "query = \"In LangGraph, what is a workflow?\"\n",
    "results = retriever.invoke(query)  # returns List[Document]\n",
    "\n",
    "def preview(text, n=500):\n",
    "    text = (text or \"\").replace(\"\\n\", \" \")\n",
    "    return text[:n] + (\"‚Ä¶\" if len(text) > n else \"\")\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    meta = getattr(doc, \"metadata\", {}) or {}\n",
    "    src = meta.get(\"source\") or meta.get(\"url\") or meta.get(\"Source\") or \"Unknown source\"\n",
    "    print(f\"[{i}] Source: {src}\")\n",
    "    print(preview(doc.page_content))\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0a7a99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retriever tool created!\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# üõ†Ô∏è Step 1: Import Retriever Tool Builder\n",
    "# ------------------------------------------------\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "# ------------------------------------------------\n",
    "# üõ†Ô∏è Step 2: Wrap Retriever as a Tool\n",
    "# ------------------------------------------------\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever=retriever,                         # the retriever we built from FAISS\n",
    "    name=\"retriever_vector_from_db1\",            # unique tool name (used by agents)\n",
    "    description=\"Search and retrieve information about LangGraph articles\"  \n",
    ")\n",
    "\n",
    "print(\"‚úÖ Retriever tool created!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ac6e08",
   "metadata": {},
   "source": [
    "### Langchain Blogs- Seperate Vector Store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c2ed2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 3 documents from 3 URLs\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# üåê Load LangChain Documents from Web Sources\n",
    "# ------------------------------------------------\n",
    "\n",
    "# 1. Define list of URLs to fetch content from\n",
    "langchain_urls = [\n",
    "    \"https://python.langchain.com/docs/tutorials/\",\n",
    "    \"https://www.analyticsvidhya.com/blog/2025/07/langchain-fitness-coach/\",\n",
    "    \"https://jordan-mungujakisa.medium.com/creating-an-ai-blog-post-generator-with-langchain-a-step-by-step-guide-b96e896c89c0\"\n",
    "]\n",
    "\n",
    "\n",
    "# 2. Load documents from each URL using WebBaseLoader\n",
    "docs=[WebBaseLoader(url).load() for url in langchain_urls]\n",
    "print(f\"‚úÖ Loaded {len(docs)} documents from {len(langchain_urls)} URLs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1e45106-3b2e-4370-a28b-75e0a735dfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded: 3\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# üóÇÔ∏è Flatten the List of Documents\n",
    "# ------------------------------------------------\n",
    "\n",
    "# docs currently looks like: [[doc1, doc2], [doc3], [doc4, doc5, ...]]\n",
    "# We need a single flat list of documents\n",
    "\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "print(f\"Total documents loaded: {len(docs_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f834d0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created 135 chunks from 3 documents\n",
      "‚úÖ Vectorstore for LangChain created\n",
      "‚úÖ Retriever for LangChain is ready!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------\n",
    "# ‚úÇÔ∏è Step 1: Split Documents into Chunks\n",
    "# ------------------------------------------------\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,   # maximum characters per chunk\n",
    "    chunk_overlap=100  # overlap between chunks (keeps context flow)\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "print(f\"‚úÖ Created {len(doc_splits)} chunks from {len(docs_list)} documents\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# üóÑÔ∏è Step 2: Build Vector Database (FAISS)\n",
    "# ------------------------------------------------\n",
    "vectorstore_langchain = FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Vectorstore for LangChain created\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# üîç Step 3: Create Retriever\n",
    "# ------------------------------------------------\n",
    "retriever_langchain = vectorstore_langchain.as_retriever()\n",
    "\n",
    "print(\"‚úÖ Retriever for LangChain is ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c3073cc-08aa-436b-8507-8ea46c9d02bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Source: https://www.analyticsvidhya.com/blog/2025/07/langchain-fitness-coach/\n",
      "Use Cases for Langchain\n",
      "--------------------------------------------------------------------------------\n",
      "[2] Source: https://www.analyticsvidhya.com/blog/2025/07/langchain-fitness-coach/\n",
      "Langchain enables you to do much more when building advanced AI applications by combining large language models (LLMs) with tools, data sources, and memory. Instead of invoking the LLM with a plain text prompt, you can create agents that invoke functions, query information, and manage conversations with state. For a fitness coach, Langchain allows you to combine LLM intelligence with custom logic ‚Äì for example, create workout suggestions, track progress, and get health data ‚Äì so you can be a\n",
      "--------------------------------------------------------------------------------\n",
      "[3] Source: https://python.langchain.com/docs/tutorials/\n",
      "Tutorials | ü¶úÔ∏èüîó LangChain\n",
      "--------------------------------------------------------------------------------\n",
      "[4] Source: https://python.langchain.com/docs/tutorials/\n",
      "Skip to main contentThese docs will be deprecated and no longer maintained with the release of LangChain v1.0 in October 2025. Visit the v1.0 alpha docsIntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1üí¨SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# üîç Ask the retriever (tuned) and show readable results\n",
    "# ------------------------------------------------\n",
    "\n",
    "\n",
    "query = \"what is langchain?\"\n",
    "results = retriever_langchain.invoke(query)  # returns List[Document]\n",
    "\n",
    "def preview(text, n=500):\n",
    "    text = (text or \"\").replace(\"\\n\", \" \")\n",
    "    return text[:n] + (\"‚Ä¶\" if len(text) > n else \"\")\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    meta = getattr(doc, \"metadata\", {}) or {}\n",
    "    src = meta.get(\"source\") or meta.get(\"url\") or meta.get(\"Source\") or \"Unknown source\"\n",
    "    print(f\"[{i}] Source: {src}\")\n",
    "    print(preview(doc.page_content))\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf70c2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangChain retriever tool created successfully!\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# üõ†Ô∏è Step 1: Import Retriever Tool Builder\n",
    "# ------------------------------------------------\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "# ------------------------------------------------\n",
    "# üõ†Ô∏è Step 2: Wrap LangChain Retriever as a Tool\n",
    "# ------------------------------------------------\n",
    "retriever_tool_langchain = create_retriever_tool(\n",
    "    retriever=retriever_langchain,                 # our FAISS retriever for LangChain docs\n",
    "    name=\"retriever_vector_from_db2\",              # unique name for this retriever tool\n",
    "    description=\"Search and retrieve information about LangChain\"  \n",
    ")\n",
    "\n",
    "print(\"‚úÖ LangChain retriever tool created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edbc7887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tools ready: 2 retrievers available\n",
      "- retriever_vector_from_db1: Search and retrieve information about LangGraph articles\n",
      "- retriever_vector_from_db2: Search and retrieve information about LangChain\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# üß∞ Collect All Tools\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Combine both retriever tools into one list\n",
    "tools = [\n",
    "    retriever_tool,            # LangGraph retriever\n",
    "    retriever_tool_langchain   # LangChain retriever\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Tools ready: {len(tools)} retrievers available\")\n",
    "for t in tools:\n",
    "    print(f\"- {t.name}: {t.description}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760a65ca",
   "metadata": {},
   "source": [
    "### LangGraph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "127c309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AgentState schema defined\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# üß© Step 1: Import Dependencies\n",
    "# ------------------------------------------------\n",
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# ------------------------------------------------\n",
    "# üß© Step 2: Define the Agent's State\n",
    "# ------------------------------------------------\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    Defines the structure of the agent's memory/state.\n",
    "    \n",
    "    - messages: A sequence of chat messages exchanged between user and agent.\n",
    "    - Annotated[...] + add_messages: ensures that when state updates happen,\n",
    "      new messages are appended instead of replacing the old ones.\n",
    "    \"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "print(\"‚úÖ AgentState schema defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b581a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM Response: Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# ü§ñ Step 1: Import Chat Model\n",
    "# ------------------------------------------------\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ------------------------------------------------\n",
    "# ü§ñ Step 2: Initialize the LLM\n",
    "# ------------------------------------------------\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano-2025-04-14\",  # pick your model\n",
    "    temperature=0.7,                   # controls randomness (0 = deterministic)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# ü§ñ Step 3: Quick Sanity Check\n",
    "# ------------------------------------------------\n",
    "response = llm.invoke(\"Hi\")\n",
    "print(\"‚úÖ LLM Response:\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5176f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent node function defined\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# ü§ñ Define the Agent Node Function\n",
    "# ------------------------------------------------\n",
    "\n",
    "\n",
    "def agent(state):\n",
    "    \"\"\"\n",
    "    Agent node that invokes the LLM and decides whether to:\n",
    "      - Use retriever tools (LangGraph / LangChain knowledge bases), or\n",
    "      - Respond directly without tool use.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current agent state containing chat messages.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated state with the agent's response appended to messages.\n",
    "    \"\"\"\n",
    "    print(\"--- CALL AGENT ---\")\n",
    "    \n",
    "    # Extract current conversation\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # Initialize the LLM\n",
    "    model = ChatOpenAI(\n",
    "        model=\"gpt-4.1-nano-2025-04-14\",\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    # Bind retriever tools so the model can decide when to use them\n",
    "    model = model.bind_tools(tools)\n",
    "\n",
    "    # Invoke the LLM with conversation history\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # Return response appended as a list (LangGraph expects list appending)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "print(\"‚úÖ Agent node function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67749188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# üì¶ Imports for Agent Workflow\n",
    "# ------------------------------------------------\n",
    "\n",
    "# üîπ Typing and schemas\n",
    "from typing import Annotated, Literal, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# üîπ LangChain core primitives\n",
    "from langchain import hub\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# üîπ Validation / structured outputs\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b41d12b7-5a75-4f23-bea2-123f4b5b74f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# üîó Edge Function: Grade Retrieved Documents\n",
    "# ------------------------------------------------\n",
    "from typing import Literal\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "    Returns:\n",
    "        \"generate\" if docs are relevant,\n",
    "        \"rewrite\" if docs are not relevant.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"--- CHECK RELEVANCE ---\")\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # üß© Step 1: Define Output Schema\n",
    "    # ------------------------------------------------\n",
    "    class Grade(BaseModel):\n",
    "        \"\"\"Binary score for relevance check.\"\"\"\n",
    "        binary_score: str = Field(description=\"Relevance score: 'yes' or 'no'\")\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # üß© Step 2: Initialize LLM with Structured Output\n",
    "    # ------------------------------------------------\n",
    "    model = ChatOpenAI(model=\"gpt-4.1-nano-2025-04-14\", temperature=0)\n",
    "    llm_with_tool = model.with_structured_output(Grade)\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # üß© Step 3: Define Relevance Prompt\n",
    "    # ------------------------------------------------\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "\n",
    "    # Build the chain\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # üß© Step 4: Extract Question & Docs from State\n",
    "    # ------------------------------------------------\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]         # retrieved docs (or agent response)\n",
    "    question = messages[0].content      # original user query\n",
    "    docs = last_message.content         # doc contents to grade\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # üß© Step 5: Run the Grader\n",
    "    # ------------------------------------------------\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "    score = scored_result.binary_score.lower()\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # üß© Step 6: Decision\n",
    "    # ------------------------------------------------\n",
    "    if score == \"yes\":\n",
    "        print(\"--- DECISION: DOCS RELEVANT ---\")\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        print(\"--- DECISION: DOCS NOT RELEVANT ---\")\n",
    "        return \"rewrite\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "884aa9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# üìù Node: Generate Final Answer\n",
    "# ------------------------------------------------\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate a final answer from retrieved documents and user question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): Current state containing conversation messages.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated state with the generated answer appended.\n",
    "    \"\"\"\n",
    "    print(\"--- GENERATE ---\")\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # üß© Step 1: Extract Question & Retrieved Docs\n",
    "    # ------------------------------------------------\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content        # user question\n",
    "    last_message = messages[-1]           # retrieved documents or agent response\n",
    "    docs = last_message.content\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # üß© Step 2: Load Prompt Template\n",
    "    # ------------------------------------------------\n",
    "    # rlm/rag-prompt is a community template for RAG-style answers\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # üß© Step 3: Initialize LLM\n",
    "    # ------------------------------------------------\n",
    "    llm = ChatOpenAI(model=\"gpt-4.1-nano-2025-04-14\", temperature=0)\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # üß© Step 4: Define Chain (Prompt ‚Üí LLM ‚Üí Parser)\n",
    "    # ------------------------------------------------\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # üß© Step 5: Run Chain\n",
    "    # ------------------------------------------------\n",
    "    response = rag_chain.invoke({\n",
    "        \"context\": docs,\n",
    "        \"question\": question\n",
    "    })\n",
    "\n",
    "    # LangGraph expects list so we wrap response\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa2a563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# üîÑ Node: Rewrite Query\n",
    "# ------------------------------------------------\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Reformulate the user query into a better, clearer version\n",
    "    if retrieved documents were not relevant.\n",
    "\n",
    "    Args:\n",
    "        state (dict): Current state containing conversation messages.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated state with the rewritten question appended.\n",
    "    \"\"\"\n",
    "    print(\"--- TRANSFORM QUERY ---\")\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # üß© Step 1: Extract the Original Question\n",
    "    # ------------------------------------------------\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # üß© Step 2: Build Rewriting Prompt\n",
    "    # ------------------------------------------------\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\"\n",
    "            Look at the input and reason about the underlying semantic intent.  \n",
    "            Here is the initial question:\n",
    "            -------------------\n",
    "            {question}\n",
    "            -------------------\n",
    "            Please rewrite this into a clearer, improved question.\n",
    "            \"\"\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # üß© Step 3: Call LLM to Rewrite\n",
    "    # ------------------------------------------------\n",
    "    model = ChatOpenAI(model=\"gpt-4.1-nano-2025-04-14\", temperature=0.3)\n",
    "    response = model.invoke(msg)\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # üß© Step 4: Return Updated State\n",
    "    # ------------------------------------------------\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26bbd7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Workflow compiled and visualized.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# üï∏Ô∏è Build the LangGraph Workflow (Nodes + Edges)\n",
    "# ------------------------------------------------\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 1) Initialize the stateful workflow with our AgentState\n",
    "# ------------------------------------------------\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2) Register Nodes\n",
    "#    - \"agent\": decides to use tools or answer directly\n",
    "#    - \"retrieve\": executes retriever tools (LangGraph + LangChain)\n",
    "#    - \"rewrite\": improves the user query if retrieval was irrelevant\n",
    "#    - \"generate\": synthesizes final answer from retrieved docs\n",
    "# ------------------------------------------------\n",
    "workflow.add_node(\"agent\", agent)\n",
    "\n",
    "# Use the tools list you previously created: tools = [retriever_tool, retriever_tool_langchain]\n",
    "retrieve_node = ToolNode(tools)\n",
    "workflow.add_node(\"retrieve\", retrieve_node)\n",
    "\n",
    "workflow.add_node(\"rewrite\", rewrite)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3) Entry Edge: START -> agent\n",
    "# ------------------------------------------------\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4) Conditional from agent:\n",
    "#    - If model decides to use tools -> go to \"retrieve\"\n",
    "#    - If model ends (no tool)      -> END\n",
    "# ------------------------------------------------\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,                 # inspects the agent output for tool usage\n",
    "    {\n",
    "        \"tools\": \"retrieve\",         # when tools are requested\n",
    "        END: END,                    # when agent chooses to finish\n",
    "    },\n",
    ")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 5) Conditional after retrieve:\n",
    "#    - grade_documents returns \"generate\" or \"rewrite\"\n",
    "# ------------------------------------------------\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    grade_documents,                 # returns \"generate\" or \"rewrite\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 6) Final Edges\n",
    "# ------------------------------------------------\n",
    "workflow.add_edge(\"generate\", END)   # after generating, finish\n",
    "workflow.add_edge(\"rewrite\", \"agent\")# after rewriting, try agent again\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 7) Compile the graph and visualize\n",
    "# ------------------------------------------------\n",
    "graph = workflow.compile()\n",
    "\n",
    "# Visualize the compiled graph (Mermaid PNG)\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "print(\"‚úÖ Workflow compiled and visualized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "661decb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CALL AGENT ---\n",
      "--- CHECK RELEVANCE ---\n",
      "--- DECISION: DOCS RELEVANT ---\n",
      "--- GENERATE ---\n",
      "‚úÖ Graph execution completed\n",
      "\n",
      "üí° Answer:\n",
      " LangGraph is a tool within the LangChain ecosystem used to assemble LangChain components into full-featured applications. It facilitates orchestration of these components to build complex AI applications. It is part of the broader set of tools and guides available for developing with LangChain.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# ‚ñ∂Ô∏è Run the Workflow\n",
    "# ------------------------------------------------\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Wrap the input in a HumanMessage\n",
    "input_state = {\n",
    "    \"messages\": [HumanMessage(content=\"What is LangGraph?\")]\n",
    "}\n",
    "\n",
    "# Invoke the workflow\n",
    "result = graph.invoke(input_state)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# üìå Show Final Answer\n",
    "# ------------------------------------------------\n",
    "print(\"‚úÖ Graph execution completed\\n\")\n",
    "final_answer = result[\"messages\"][-1].content\n",
    "print(\"üí° Answer:\\n\", final_answer)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "448a376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CALL AGENT ---\n",
      "--- CHECK RELEVANCE ---\n",
      "--- DECISION: DOCS RELEVANT ---\n",
      "--- GENERATE ---\n",
      "‚úÖ Graph execution completed\n",
      "\n",
      "LangChain is a framework that enables the development of advanced AI applications by integrating large language models (LLMs) with tools, data sources, and memory. It allows creating agents that can invoke functions, query information, and manage conversations with state. Essentially, it helps build more interactive and intelligent AI systems.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# ‚ñ∂Ô∏è Run Workflow with LangChain Question\n",
    "# ------------------------------------------------\n",
    "\n",
    "\n",
    "# Wrap the input as a HumanMessage inside a list\n",
    "input_state = {\n",
    "    \"messages\": [HumanMessage(content=\"What is LangChain?\")]\n",
    "}\n",
    "\n",
    "# Invoke the workflow\n",
    "result = graph.invoke(input_state)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# üìå Show Only Final Answer\n",
    "# ------------------------------------------------\n",
    "print(\"‚úÖ Graph execution completed\\n\")\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c03cb88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CALL AGENT ---\n",
      "--- CHECK RELEVANCE ---\n",
      "--- DECISION: DOCS RELEVANT ---\n",
      "--- GENERATE ---\n",
      "Machine learning is a subset of artificial intelligence that involves developing algorithms and models that enable computers to learn from and make decisions based on data. It encompasses techniques like supervised, unsupervised, and reinforcement learning to identify patterns and improve performance over time. It serves as the foundation for many advanced AI applications, including generative AI and large language models.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Input query\n",
    "input_state = {\n",
    "    \"messages\": [HumanMessage(content=\"What is Machine learning?\")]\n",
    "}\n",
    "\n",
    "# Run the workflow\n",
    "result = graph.invoke(input_state)\n",
    "\n",
    "# ‚úÖ Print only the final answer content\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2427a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
